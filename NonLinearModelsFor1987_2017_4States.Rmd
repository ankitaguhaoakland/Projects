---
title: "Comparing Predictive Non Linear Modelling For Air Quality Data of 4 US States for the year of 1987 & 2017"
output: html_document
author: "Ankita Guha, Kara Marsh"
Date: April 22, 2018
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Loading a few libraries
```{r}
library(plyr)
library(dplyr)
library(ggplot2)
library(useful)
library(coefplot)
library(caret)
library(lattice)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(class)
library(randomForest)
library(reshape2)
library(glmnet)
```

**Data Preparation**
```{r}
aq4States1 <- read.table("eda2_States.csv", header = TRUE, sep = ",")
aq4States1$X <-NULL

aq4States <- aq4States1 %>% filter(year == "1987" | year == "2017")


# Creating Another Collumn With Pollutant as Binary Variable  
nrow(na.omit(aq4States1))

for(i in 1:nrow(aq4States)){
  if(aq4States$method_name[i] == "Ozone"){
    aq4States$Pollutant[i] <- 1
  }else{
    aq4States$Pollutant[i] <- 0
  }
}

aq4States$Pollutant <- as.factor(ifelse(aq4States$parameter_name=="Ozone",1,0))
str(aq4States)
head(aq4States)
rm(aq4States1)
```


```{r}
aq4States$parameter_name <- NULL
aq4States$method_name <- NULL
str(aq4States)
summary(aq4States)
```


Now we'll just take a subset of the columns as there are a few that contain the same information. Remember, the new column `Pollutant` is the one we are trying to predict.

```{r}
set.seed(828)
sample_size <- ceiling(0.30 * nrow(aq4States))
testrecs <- sample(nrow(aq4States),sample_size)
Ozone_test <- aq4States[testrecs,]
Ozone_train <- aq4States[-testrecs,] 

```



```{r}
Ozone_LogM1 <- glm(Pollutant ~  .,
                    data=Ozone_train, family=binomial(link="logit"), control = list(maxit = 50))

summary(Ozone_LogM1)
```

Looks like our Model has fitted well, since the Residual deviance value is less than the value of Null deviance.
Converting probabilities to 0 and 1 for predictions.
```{r}
yhat_LogM1 <- (Ozone_LogM1$fit > 0.5) * 1
```

Putting the fitted and the predicted values into a dataframe for ease of analysis
```{r}
Ozone_fit_predictions <- data.frame(Ozone_LogM1$y, yhat_LogM1)
names(Ozone_fit_predictions) <- c("yact","yhat_LogM1")
```


## Creating Confusion Matrix
```{r}
# Confusion Matrix
table(Ozone_fit_predictions$yact, Ozone_fit_predictions$yhat_LogM1)

# Percentage of Precision and Recall 
prop.table(table(Ozone_fit_predictions$yact, Ozone_fit_predictions$yhat_LogM1))
```


```{r}
cm_LogM1 <- confusionMatrix(Ozone_fit_predictions$yhat_LogM1, Ozone_fit_predictions$yact, 
                            positive = "1")
cm_LogM1
```
Looks like our Model has an Accuracy of 87% and the Sensitivity or the Probability of True Positive is only 53% at the 95% confidence interval. And looks like our Confidence Interval is also a tight fit indicating that our Rsquare Value or our Accuracy of Model Fit is a good fit at 95% confidence interval.

## Predictions on Test Data for Model 1: Logistic Regression
```{r}
prob_LogM1 <- predict(Ozone_LogM1, newdata=Ozone_test, type="response", se.fit=FALSE)
pred_LogM1 <- (prob_LogM1 > 0.5) * 1
head(pred_LogM1)
```

Let's free some of our Memory space
```{r}
rm(Ozone_LogM1)
```


**Simple Decision Tree**
```{r}
Ozone_tree <- rpart(Pollutant ~ ., data=Ozone_train, method="class")

# Visualize the tree with rpart.plot
rpart.plot(Ozone_tree)
```

```{r}
## Creating Confusion Matrix

Ozone_fit_predictions$yhat_tree <- predict(Ozone_tree, type = "class")

# Confusion Matrix
table(Ozone_fit_predictions$yact, Ozone_fit_predictions$yhat_tree)

# Percentage of Precision and Recall 
prop.table(table(Ozone_fit_predictions$yact, Ozone_fit_predictions$yhat_tree))
```


```{r}
cm_tree <- confusionMatrix(Ozone_fit_predictions$yhat_tree, Ozone_fit_predictions$yact, 
                            positive = "1")
cm_tree
```
Looks like our Model has an Accuracy of 97% and the Sensitivity or the Probability of True Positive is also 97% at the 95% confidence interval. And looks like our Confidence Interval is also a tight fit indicating that our Rsquare Value or our Accuracy of Model Fit is a good fit at 95% confidence interval.

## Predictions on Test Data for Model 2: Simple Decision Tree
```{r}
pred_tree <- predict(Ozone_tree, newdata=Ozone_test, type="class")
head(pred_tree)
```
# Model 3: Random Forest
```{r}
rand_forest <- randomForest(Pollutant ~ ., data=Ozone_train, method = "class")
rand_forest
```

## Creating Confusion Matrix
```{r}
Ozone_fit_predictions$yhat_rf <- predict(rand_forest, type = "class")

# Confusion matrix
table(Ozone_fit_predictions$yact, Ozone_fit_predictions$yhat_rf)

# Percentage of Precision and Recall 
prop.table(table(Ozone_fit_predictions$yact, Ozone_fit_predictions$yhat_rf))
```

```{r}
cm_rf <- confusionMatrix(Ozone_fit_predictions$yhat_rf, Ozone_fit_predictions$yact, 
                            positive = "1")
cm_rf
```
Looks like our Model has an Accuracy of 98% and the Sensitivity or the Probability of True Positive is 95% at the 95% confidence interval. And looks like our Confidence Interval is also a tight fit indicating that our Rsquare Value or our Accuracy of Model Fit is a good fit at 95% confidence interval.

## Predictions on Test Data for Model 3: Random Forest
```{r}
pred_rf <- predict(rand_forest, newdata=Ozone_test, type="class")
head(pred_rf)
```


Then use the `predict()` function to make classification predictions on the
test dataset and use `caret::confusionMatrix` to create a confusion matrix
for each of the models for the predictions. 

## Summarizing 

Now let’s gather the three sets of prediction along with the actual values into its own dataframe.
```{r}
pred_results <- as.data.frame(cbind(pred_LogM1, 
                                    pred_tree, pred_rf, Ozone_test$Pollutant))

names(pred_results) <- c("pred_LogM1", "pred_tree", "pred_rf","test_Pollutant")
head(pred_results)
```

Hmmm, looks like the values are the level numbers. Let’s just adjust to match our logistic regression predictions for the rest of our Models.

```{r}
pred_results$pred_tree <- pred_results$pred_tree - 1
pred_results$pred_rf <- pred_results$pred_rf - 1
pred_results$test_Pollutant <- pred_results$test_Pollutant - 1
head(pred_results)
```
Now let’s just create a confusion matrix for each model and the actual values from the Ozone_test dataset and compare their performance.

```{r}
cm_predLogM1 <- confusionMatrix(pred_results$pred_LogM1, 
                                 pred_results$test_Pollutant, 
                                 positive = "1")

cm_predtree <- confusionMatrix(pred_results$pred_tree, 
                                pred_results$test_Pollutant, 
                                positive = "1")

cm_predrf <- confusionMatrix(pred_results$pred_rf, 
                                pred_results$test_Pollutant, 
                                positive = "1")
```

## Confusion Matrix for Predicted Model 1: Logistic Regression
```{r}
cm_predLogM1
```

## Confusion Matrix for Predicted Model 2: Simple Decision Tree
```{r}
cm_predtree
```

## Confusion Matrix for Predicted Model 3: Random Forest
```{r}
cm_predrf
```
## Accuracy & Sensitivity for all the Fitted Models
```{r}
# Model 1: Logistic Regression
sprintf("Model 1 - Logistic Regression: Accuracy = %8.4f Sensitivity = %8.4f", 
        cm_LogM1$overall["Accuracy"],
        cm_LogM1$byClass["Sensitivity"])
```

```{r}
# Model 2: Simple Decision Tree
sprintf("Model 2 - Simple Decision Tree: Accuracy = %8.4f Sensitivity = %8.4f", 
        cm_tree$overall["Accuracy"],
        cm_tree$byClass["Sensitivity"])
```

```{r}
# Model 3: Random Forest
sprintf("Model 3 - Random Forest: Accuracy = %8.4f Sensitivity = %8.4f", 
        cm_rf$overall["Accuracy"],
        cm_rf$byClass["Sensitivity"])
```

## Accuracy & Sensitivity for all the Predicted Models
```{r}
# Model 1: Logistic Regression
sprintf("Model 1 - Logistic Regression: Accuracy = %8.4f Sensitivity = %8.4f", 
        cm_predLogM1$overall["Accuracy"],
        cm_predLogM1$byClass["Sensitivity"])
```

```{r}
# Model 2: Simple Decision Tree
sprintf("Model 2 - Simple Decision Tree: Accuracy = %8.4f Sensitivity = %8.4f", 
        cm_predtree$overall["Accuracy"],
        cm_predtree$byClass["Sensitivity"])
```

```{r}
# Model 3: Random Forest
sprintf("Model 3 - Random Forest: Accuracy = %8.4f Sensitivity = %8.4f", 
        cm_predrf$overall["Accuracy"],
        cm_predrf$byClass["Sensitivity"])
```

**Conclusion**
+ Best Model Accuracy: Simple Decision Tree
+ Best Model Sensitivity: Random Forest

