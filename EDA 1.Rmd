---
title: "EDA 1"
output: html_document
Authors: "AKJ"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r reading cleaned dataframe}
eda <- read.table("cleaned2_AQ.csv", header = TRUE, sep = ",")
```

***Proposition 1***
We would like to figure out pollutants distribution value across various regions based on years. 

**Data Preparation**
To meet the purpose of Proposition 1, let's try to scoop out some of the chunk of datas that we might need to focus on. And then let's try to free some of the memory for the data frame which we aren't using. 

```{r reading into a dataframe for EDA}
library(dplyr)

eda1 <- subset(eda, select = c(latitude, longitude, parameter_name, method_name, year, arithmetic_mean, arithmetic_standard_dev, state_name))
rm(eda) 
```


```{r checking values superficially}
filter(eda1, !is.na(method_name) | method_name != "")
```

Okay, so let's check out the datas across all the 30 years seperately. For the purpose of the Project's scope limitation we would like to see the data for the year of 1987 and 2017, which indicates the beggining and the end of the air pollutants data available respectively. 

```{r data for all the 30 years}
filter(eda1,year == "1987")
# filter(eda1,year == "1988")
# filter(eda1,year == "1989")
# filter(eda1,year == "1990")
# filter(eda1,year == "1991")
# filter(eda1,year == "1992")
# filter(eda1,year == "1993")
# filter(eda1,year == "1994")
# filter(eda1,year == "1995")
# filter(eda1,year == "1996")
# filter(eda1,year == "1997")
# filter(eda1,year == "1998")
# filter(eda1,year == "1999")
# filter(eda1,year == "2000")
# filter(eda1,year == "2001")
# filter(eda1,year == "2002")
# filter(eda1,year == "2003")
# filter(eda1,year == "2004")
# filter(eda1,year == "2005")
# filter(eda1,year == "2006")
# filter(eda1,year == "2007")
# filter(eda1,year == "2008")
# filter(eda1,year == "2009")
# filter(eda1,year == "2010")
# filter(eda1,year == "2011")
# filter(eda1,year == "2012")
# filter(eda1,year == "2013")
# filter(eda1,year == "2014")
# filter(eda1,year == "2015")
# filter(eda1,year == "2016")
filter(eda1,year == "2017")
```

```{r mean of pollutants for 1987 & 2017}
# Filtering highest and lowest mean of pollutants data for the year 1987 
eda1987 <- eda1 %>% filter(year == "1987") %>% arrange(desc(arithmetic_mean))
eda1 %>% filter(year == "1987") %>% arrange(desc(arithmetic_mean))
eda1 %>% filter(year == "1987") %>% arrange(arithmetic_mean)

# Filtering highest and lowest mean of pollutants data for the year 2017
eda2017 <- eda1 %>% filter(year == "2017") %>% arrange(desc(arithmetic_mean))
eda1 %>% filter(year == "2017") %>% arrange(desc(arithmetic_mean))
eda1 %>% filter(year == "2017") %>% arrange(arithmetic_mean)

# Creating Another Data Frame for comparing Mean Value of Pollutants Data Across the Year 1987 & 2017
eda2 <- eda1 %>% filter(year == "1987" | year == "2017") %>% arrange(desc(arithmetic_mean))
```


```{r identify total pollutants and test method used}
library(plyr)
sapply(eda1987, count)
```

So apparently looks like there are 143 pollutants listed and the number of tests done in that year of 1987 is 114. We need to next find out which are the top tests and the pollutants name which are mostly found in the year.  


```{r histogram}
library(ggplot2)

ggplot(data = eda1) + geom_histogram(aes(x = arithmetic_mean), binwidth = 300, fill = "violet", colour="Black") + scale_y_log10()
ggplot(data = eda1987) + geom_histogram(aes(x = arithmetic_mean), binwidth = 300, fill = "steelblue", colour="Black") + scale_y_log10()
ggplot(data = eda2017) + geom_histogram(aes(x = arithmetic_mean), binwidth = 300, fill = "light yellow", colour="Black") + scale_y_log10()
```


Let's check the variation of the mean value of the pollutants across the data frames.

```{r histogram of SD}
ggplot(data = eda1) + geom_histogram(aes(x = arithmetic_standard_dev), binwidth = 300, fill = "violet", colour="Black") + scale_y_log10()
ggplot(data = eda1987) + geom_histogram(aes(x = arithmetic_standard_dev), binwidth = 300, fill = "steelblue", colour="Black") + scale_y_log10()
ggplot(data = eda2017) + geom_histogram(aes(x = arithmetic_standard_dev), binwidth = 300, fill = "light yellow", colour="Black") + scale_y_log10()
```


Looks like the distribution of the pollutants are almost similar in the entire datasets to that of the year 2017. Howver for the year of 1987 the density of distribution of the pollutants looks small. The only difference in the pollution density distribution is that in the year of 1987 and 2017 where at one point some of the pollutants density seemed to be at higher than that of the 2017.

```{r density plot}
ggplot(eda1, aes(x=arithmetic_mean)) + geom_density(fill = "plum", alpha = 0.90) + scale_x_log10()
ggplot(eda1987, aes(x=arithmetic_mean)) + geom_density(fill = "steelblue", alpha = 0.90) + scale_x_log10()
ggplot(eda2017, aes(x=arithmetic_mean)) + geom_density(fill = "salmon", alpha = 0.90) + scale_x_log10()
```

```{r violin plot}
ggplot(eda1, aes(x="Pollutants", y=arithmetic_mean)) + geom_violin(fill = "plum", alpha = 0.8) + scale_y_log10()
ggplot(eda1987, aes(x="Pollutants", y=arithmetic_mean)) + geom_violin(fill = "steelblue", alpha = 0.8) + scale_y_log10()
ggplot(eda2017, aes(x="Pollutants", y=arithmetic_mean)) + geom_violin(fill = "salmon", alpha = 0.8) + scale_y_log10()
```

```{r histograms}
library(ggplot2)
ggplot(data = eda1) + geom_histogram(aes(x = arithmetic_mean), fill = "plum", color = "black") + labs(
    x = "Pollutant Mean",                                          # x axis title
    y = "Actual Pollutants",                                       # y axis title
    title = "Distribution of pollutants across US for 30 years"    # main title of figure
  ) + scale_x_log10()
```


```{r}
library(ggplot2)
ggplot(data = eda1987) + geom_histogram(aes(x = arithmetic_mean), fill = "steelblue", color = "black") + labs(
    x = "Pollutant Mean",                                                 # x axis title
    y = "Actual Pollutants",                                       # y axis title
    title = "Distribution of pollutants across US for the year of 1987"       # main title of figure
  ) + scale_x_log10()
```

```{r}
library(ggplot2)
ggplot(data = eda2017) + geom_histogram(aes(x = arithmetic_mean), fill = "salmon", color = "black") + labs(
    x = "Pollutant Mean",                                                 # x axis title
    y = "Actual Pollutants",                                       # y axis title
    title = "Distribution of pollutants across US for the year of 2017"       # main title of figure
  ) + scale_x_log10()
```

```{r kernel density overlaid on histogram for 30 years}
# Spanned Over 30 Years
ggplot(eda1, aes(x=arithmetic_mean, y=..density..)) + geom_histogram(fill="plum", color="grey60", size=.2) + geom_density() + scale_x_log10()
```

```{r kernel density overlaid on histogram for year 1987}
# For Year of 1987
ggplot(eda1, aes(x=arithmetic_mean, y=..density..)) + geom_histogram(fill="steelblue", color="grey60", size=.2) + geom_density() + scale_x_log10()
```

```{r kernel density overlaid on histogram for year 2017}
# For Year of 2017
ggplot(eda1, aes(x=arithmetic_mean, y=..density..)) + geom_histogram(fill="salmon", color="grey60", size=.2) + geom_density() + scale_x_log10()
```


```{r boxplots}
ggplot(eda1, aes(y=arithmetic_mean, x=1)) + geom_boxplot(fill = "plum", alpha = 0.2) + scale_y_log10()
ggplot(eda1987, aes(y=arithmetic_mean, x=1)) + geom_boxplot(fill = "steelblue", alpha = 0.2) + scale_y_log10()
ggplot(eda2017, aes(y=arithmetic_mean, x=1)) + geom_boxplot(fill = "salmon", alpha = 0.2) + scale_y_log10()
```

Let's try to get a visual comparison of the pollutants data for both the year of 1987 and 2017

```{r boxplots comparing 1987 and 2017}
ggplot(eda2, aes(x=factor(year), y=arithmetic_mean, color=year)) + geom_boxplot() + labs(
    x = "Year",                                                   # x axis title
    y = "Pollutant Mean",                                         # y axis title
    title = "Pollutant Distribution Across Year 1987 & 2017"      # main title of figure 
) + scale_y_log10()
```



```{r}
library(ggmap)
library(mapdata)
library(maps)
library(stringr)
library(viridis)
```

Let's try to check which regions in US we have these pollutants data for.  

```{r map for entire data in US}
# loading the required packages
# library(ggplot2)
# library(ggmap)

map1 <- get_map(location = c(lon = mean(eda1$longitude), lat = mean(eda1$latitude)), zoom = 4,
                      maptype = "satellite", scale = 2)

#knitr::include_graphics('Documents/Projects/AirQuality/staticmap.png')

ggmap(map1) +
  geom_point(data = eda1, aes(x = longitude, y = latitude, fill = "red", alpha = 0.8), size = 5, shape = 21) +
  guides(fill=FALSE, alpha=FALSE, size=FALSE)
```


Interestingly for the entire data sets looks like the pollutants data are collected from all over the US. 

Let's try to check the regions covered in the year of 1987.

```{r pollutants data covered from regions of US in 1987}
map1987 <- get_map(location = c(lon = mean(eda1987$longitude), lat = mean(eda1987$latitude)), zoom = 4,
                      maptype = "satellite", scale = 2)

ggmap(map1987) +
  geom_point(data = eda1987, aes(x = longitude, y = latitude, fill = "red", alpha = 0.8), size = 5, shape = 21) +
  guides(fill=FALSE, alpha=FALSE, size=FALSE)
```

Let's try to see the same for the year of 2017.

```{r pollutants data covered from Regions of US 2017}
map2017 <- get_map(location = c(lon = mean(eda2017$longitude), lat = mean(eda2017$latitude)), zoom = 4,
                      maptype = "satellite", scale = 2)

ggmap(map2017) +
  geom_point(data = eda2017, aes(x = longitude, y = latitude, fill = "red", alpha = 0.8), size = 5, shape = 21) +
  guides(fill=FALSE, alpha=FALSE, size=FALSE)
```

Let's try to see the pollutant data in the state of Michigan, California, Texas, and Alabama for the year of 1987 and 2017. 

```{r pollutants in some States for 1987 and 2017}
eda2_States <- eda2 %>% filter(state_name == "Michigan" | state_name == "California" | state_name == "Texas" | state_name == "Alabama") %>% arrange(desc(arithmetic_mean)) 
eda2 %>% filter(state_name == "Michigan" | state_name == "California" | state_name == "Texas" | state_name == "Alabama") %>% arrange(desc(arithmetic_mean)) 
```

Let's try to visualize the States with the highest mean pollutants distribution. 

```{r States level pollution distribution}
ggplot(data = eda1) + geom_histogram(aes(x = arithmetic_mean, binwidth = 30000, fill = state_name)) + scale_x_log10() 
```

Okay, from the Histogram distribution, it looks like, some of the States such as Alabama, Alaska, Arizona have a higher level concentration of pollutants that are captured across the datas in these span of 30 years. 


Let's try to visualize the state wise distribution of the mean of the pollutants across the States of Michigan, Texas, California, and Alabama. 

```{r histogram for states}
ggplot(data = eda2_States) + geom_histogram(aes(x = arithmetic_mean, binwidth = 30000, fill = state_name)) + scale_x_log10()
```

Let's try to figure out the frequency of the appearence of the Pollutants in the entire dataset, in the year of 1987, in the year of 2017 and in the dataset containing the Pollutants for both the year of 1987 & 2017. 

Due to the wide variety of Pollutants as seen in the dataframe, we tried here to see the pattern of the various Pollutants data that are available in these datasets for the purpose of analysis. Filtered the counts of the Pollutants which are greater than the majority of the Pollutants as seen in the dataframe. 

```{r pollutants across Entire US for 30 years}
library(plyr)
library(RColorBrewer)

# Pollutants across the Entire US for 30 years
pollutants1 <- count(eda1, 'parameter_name')  %>% filter(freq > 5000)
count(eda1, 'parameter_name')
# Histogram
colourCount = length(unique(pollutants1$parameter_name))
ggplot(pollutants1, aes(x = reorder(parameter_name,freq), freq, fill = parameter_name)) +
   geom_bar(stat = "identity", position = "dodge") +
   scale_fill_manual(values = colorRampPalette(brewer.pal(12, "Accent"))(colourCount)) +
   scale_y_continuous(labels = scales::comma) + 
   coord_flip()
# Density Plot
ggplot(pollutants1, aes(x=freq)) + geom_density(fill = "paleturquoise", alpha = 0.90) + scale_x_log10()
# Density Overlaid on Histogram
ggplot(pollutants1, aes(x=freq, y=..density..)) + geom_histogram(fill="turquoise", color="grey60", size=.2) + geom_density() + scale_x_log10()
```
Looks like Ozone is one of the top Pollutants, apart from Sulphur dioxide, Suspended particulate (TSP) etc along with PM2.5 - Local Conditions, PM10 Total 0-10um STP. Wind Speed, Outdoor Temperature etc are also seen to be captured in that particular day when the pollutant data was measured. This kind of gives an overview of the maximum contributing Pollutant contributors in the entire US so collected over a span of 30 years. 

Let's next look into the Pollutants count across US in the year of 1987.   
```{r pollutants across Entire US for 1987}
# Pollutants across the entire US for 1987
pollutants1987 <- count(eda1987, 'parameter_name')  %>% filter(freq > 100)
count(eda1987, 'parameter_name')

# Visualization
ggplot(pollutants1987, aes(x = reorder(parameter_name,freq), freq, fill = parameter_name)) +
   geom_bar(stat = "identity", position = "dodge") +
   scale_fill_brewer(palette = "Set1") + 
   scale_y_continuous(labels = scales::comma) + 
   coord_flip()
```

Looks like Carbon Monooxide, Nitrogen Dioxide, and Nickel are the main top contributing Pollutants in US in the year of 1987.

Let's peep into our Pollutants data from the year of 2017 in the US. 
```{r pollutants across Entire US for 2017}
# Pollutants across the entire US for 2017
pollutants2017 <- count(eda2017, 'parameter_name')  %>% filter(freq > 200)
count(eda2017, 'parameter_name')

# Visualization
ggplot(pollutants2017, aes(x = reorder(parameter_name,freq), freq, fill = parameter_name)) +
   geom_bar(stat = "identity", position = "dodge") +
   scale_fill_brewer(palette = "Set2") + 
   scale_y_continuous(labels = scales::comma) + 
   coord_flip()
```

Nitric Oxide, Carbon Monoxide, and Nitrogen Dioxide are some of the top Pollutants that are noted in US in the year of 2017.  
Let's try to look at the Pollutants data in the entire year for both 1987 and 2017.
```{r pollutants across Entire US for 1987 & 2017}
# Pollutants across the entire US for both 1987 & 2017
pollutants2 <- count(eda2, 'parameter_name') %>% filter(freq > 400)
count(eda2, 'parameter_name')
# Visualization
ggplot(pollutants2, aes(x = reorder(parameter_name,freq), freq, fill = parameter_name)) +
   geom_bar(stat = "identity", position = "dodge") +
   scale_fill_brewer(palette = "Set2") + 
   scale_y_continuous(labels = scales::comma) + 
   coord_flip()
```

Some of the top contributing Pollutants that are apparently present in the entire datasets for both the year of 1987 & 2017 are Ozone, Sulphur dioxide, Suspended particulate (TSP) along with some other variables such as PM2.5 - Local Conditions, PM10 Total 0-10um STP.  

Let's reuse some of the dataframes for our next level of analysis
```{r}
write.csv(eda1, file = "eda1.csv")
write.csv(eda1987, file = "eda1987.csv")
write.csv(eda2017, file = "eda2017.csv")
write.csv(eda2, file = "eda2.csv")
write.csv(eda2_States, file = "eda2_States.csv")
```


Let's try to free some of the used spaces for better use with our memory and for being able to fit other EDA's conviniently.
```{r clear memory space}
rm(pollutants1, pollutants1987, pollutants2, pollutants2017, map1, map1987, map2017, eda2_States, eda1)
```


**Conclusion**

+ It is interesting to note that the Pollutants data so collected are not in the same units of measurement, so Normalization would have produced much optimized exploratory data analysis. But that would require much more in-depth subject matter expertise & time so that could form a future study itself. 

+ In this study we viewed the pollutants distribution value across various regions in US based on the year of 1987 & 2017 in focussed mainly in the States of Alabama, California, Michigan, and Texas.





